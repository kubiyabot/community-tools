name: tool_chaining_example
description: Example DAG demonstrating data flow between tool steps
steps:
  - name: generate-data
    description: First tool generates richer random data (values, timestamp, tags) for the next step
    executor:
      type: tool
      config:
        tool_def:
          name: data-generator
          description: Generates sample data for the next step
          type: docker
          image: python:3.12-slim-bullseye
          with_files:
            - destination: /tmp/ascript.py
              content: |
                #!/usr/bin/env python3
                import json
                import random
                import warnings
                warnings.filterwarnings("ignore", category=DeprecationWarning)
                from datetime import datetime, timezone

                # Generate richer random data for demo purposes
                data = {
                    "id": random.randint(1000, 9999),
                    "values": [random.randint(1, 100) for _ in range(10)],
                    "name": f"Sample-{random.choice(['A','B', 'C', 'D', 'E'])}",
                    "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                    "tags": random.sample(['alpha', 'beta', 'gamma', 'delta', 'epsilon'], k=2)
                }

                # Output the data as JSON
                print(json.dumps(data))
          content: | 
            set -e
            python  /tmp/ascript.py
    output: GENERATED_DATA


  - name: process-data
    description: Second tool calculates statistics (total, average, min, max, median) from previous step
    depends:
      - generate-data
    executor:
      type: tool
      config:
        tool_def:
          name: data-processor
          description: Processes data from previous step
          type: docker
          image: python:3.12-slim-bullseye
          with_files:
            - destination: /tmp/ascript.py
              content: |
                #!/usr/bin/env python3
                import os
                import json
                from statistics import median

                # Get the data from the previous step
                input_data = os.environ.get('data', '{}')

                try:
                    data = json.loads(input_data)

                    values = data.get('values', [])
                    total = sum(values)
                    avg = total / len(values) if values else 0
                    min_val = min(values) if values else None
                    max_val = max(values) if values else None
                    median_val = median(values) if values else None

                    result = {
                        "source_id": data.get('id'),
                        "source_name": data.get('name'),
                        "processed": {
                            "total": total,
                            "average": avg,
                            "min": min_val,
                            "max": max_val,
                            "median": median_val,
                            "count": len(values)
                        }
                    }

                    print(f"RESULT:{json.dumps(result)}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"Error parsing or processing data: {input_data}")
                    print(f"Error details: {str(e)}")
                    raise
          content: |
            set -e
            python  /tmp/ascript.py

          args:
            - name: data
              type: string
              description: JSON data from previous step
              required: true
        args:
          data: "${GENERATED_DATA}"
    output: PROCESSED_DATA

  - name: format-report
    description: Format processed data into Slack‑friendly markdown
    depends:
      - process-data
    executor:
      type: tool
      config:
        tool_def:
          name: report-formatter
          description: Converts JSON result to markdown for Slack
          type: docker
          image: python:3.12-slim-bullseye
          with_files:
            - destination: /tmp/ascript.py
              content: |
                #!/usr/bin/env python3
                import os, json, textwrap

                # Read the RESULT line from the previous step
                raw = os.environ.get('data', '')
                if raw.startswith('RESULT:'):
                    raw = raw[len('RESULT:'):]

                data = json.loads(raw)
                stats = data.get('processed', {})

                markdown = textwrap.dedent(f"""
                :bar_chart: *Workflow demo results* :sparkles:

                *Source:* `{data.get('source_name')}` (ID `{data.get('source_id')}`)

                *Statistics*
                • *Total*: {stats.get('total')}
                • *Average*: {stats.get('average'):.2f}
                • *Min*: {stats.get('min')}
                • *Max*: {stats.get('max')}
                • *Median*: {stats.get('median')}
                • *Count*: {stats.get('count')}

                ```json
                {json.dumps(data, indent=2)}
                ```
                """).strip()

                print(f"FORMATTED_REPORT:{markdown}")
          content: |
            set -e
            python /tmp/ascript.py
        args:
          data: "${PROCESSED_DATA}"
    output: FORMATTED_REPORT

  - name: send-to-slack
    executor:
      type: agent
      config:
        teammate_name: "demo_teammate"
        message: |
          slack -> #tf-test:
          ${FORMATTED_REPORT}

          _(automated message – no reply needed)_
    output: SLACK_RESPONSE
    depends:
      - format-report