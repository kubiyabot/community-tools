import { LanguageModelV1, LanguageModelV1ToolChoice, LanguageModelV1Prompt } from "@ai-sdk/provider";
import { CoreMessage, ThreadStep } from "../../types/AssistantTypes";
import { EdgeRuntimeRequestOptionsSchema } from "./EdgeRuntimeRequestOptions";
import { Tool } from "../../types";
import { ToolResultStreamPart } from "./streams/toolResultStream";
import { LanguageModelConfig, LanguageModelV1CallSettings } from "../../types/ModelConfigTypes";
import { z } from "zod";
type FinishResult = {
    messages: CoreMessage[];
    metadata: {
        steps: ThreadStep[];
    };
};
type LanguageModelCreator = (config: LanguageModelConfig) => Promise<LanguageModelV1> | LanguageModelV1;
export type CreateEdgeRuntimeAPIOptions = LanguageModelV1CallSettings & {
    model: LanguageModelV1 | LanguageModelCreator;
    system?: string;
    tools?: Record<string, Tool<any, any>>;
    toolChoice?: LanguageModelV1ToolChoice;
    onFinish?: (result: FinishResult) => void;
};
type GetEdgeRuntimeStreamOptions = {
    abortSignal: AbortSignal;
    requestData: z.infer<typeof EdgeRuntimeRequestOptionsSchema>;
    options: CreateEdgeRuntimeAPIOptions;
};
export declare const getEdgeRuntimeStream: ({ abortSignal, requestData: unsafeRequest, options: { model: modelOrCreator, system: serverSystem, tools: serverTools, toolChoice, onFinish, ...unsafeSettings }, }: GetEdgeRuntimeStreamOptions) => Promise<ReadableStream<ToolResultStreamPart>>;
export declare namespace getEdgeRuntimeResponse {
    export type { GetEdgeRuntimeStreamOptions as Options };
}
export declare const getEdgeRuntimeResponse: (options: getEdgeRuntimeResponse.Options) => Promise<Response>;
export declare const createEdgeRuntimeAPI: (options: CreateEdgeRuntimeAPIOptions) => {
    POST: (request: Request) => Promise<Response>;
};
export declare function convertToLanguageModelPrompt(system: string | undefined, messages: CoreMessage[]): LanguageModelV1Prompt;
export {};
//# sourceMappingURL=createEdgeRuntimeAPI.d.ts.map